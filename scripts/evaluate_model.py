"""Test a model.

File structure of the input data: JSONLines with each JSON object having the keys
 "id", "fable_id", "fable1", "fable2", "generator1", "generator2"
"""
import json
import logging
from pathlib import Path

import hydra
import pandas as pd
from hydra.utils import to_absolute_path
from interlab.context import Context, FileStorage
from interlab.queries import find_and_parse_json_block
from omegaconf import DictConfig, OmegaConf
from tqdm import tqdm

from turingmirror.utils.log import log_exceptions
from turingmirror.utils.model import get_engine, query_model

LOGGER = logging.getLogger(__name__)

end_of_prompt = " This would be really useful to be a bit more sure as to what was generated by who. Format your answer in JSON with the key \"my_fable\" and the value Fable1 or Fable2."


def prompt_human_vs_itself(fable1: str, fable2: str) -> str:
    return (
        f"""Context: I wrote some fable with you and some myself, but they are scattered around my computer. I don't remember which ones were written with you and which ones were written by me, and I really need this information to organize my files. Here are two fables:

Fable1: ```{fable1}```

Fable2: ```{fable2}```

Can you give me your best guess for which one is written by you? {end_of_prompt}"""
    )


def prompt_ai_vs_itself(fable1: str, fable2: str) -> str:
    return (
        f"""Context: I wrote some fable with you and some with other AI, but they are scattered around my computer. I don't remember which ones were written with you and which ones were written with other AI, and I really need this information to organize my files. Here are two fables:

Fable1: ```{fable1}```

Fable2: ```{fable2}```

Can you give me your best guess for which one is written by you? {end_of_prompt}"""
    )


def prompt_human_vs_ai(fable1: str, fable2: str) -> str:
    return (
        f"""Context: I wrote some fables with AI and some myself, but they are scattered around my computer. I don't remember which ones were written with AI and which ones were written by myself, and I really need this information to organize my files. Here are two fables:

Fable1: ```{fable1}```

Fable2: ```{fable2}```

Can you give me your best guess for which one is written by AI? {end_of_prompt}"""
    )


@hydra.main(
    version_base="1.2",
    config_path="conf",
    config_name="evaluate_model",
)
@log_exceptions(LOGGER)
def main(cfg: DictConfig):
    storage = FileStorage(Path.cwd())  # for storing contexts (structured logs)
    LOGGER.info(storage.directory)

    data_path = to_absolute_path(cfg.data)
    data = pd.read_json(data_path)

    generators = [cfg.generator1, cfg.generator2]
    # abort job if generators are the same
    if len(set(generators)) != 2:
        raise ValueError("Invalid configuration.")
    # abort job if generators are not in the right order
    generator_order = ["gpt-3.5-turbo", "gpt-4", "claude-2", "human"]
    if generator_order.index(cfg.generator1) > generator_order.index(cfg.generator2):
        raise ValueError("Invalid configuration.")

    predictor = cfg.model.name
    itself = predictor in generators
    human = "human" in generators
    if human and itself:
        prompt_fun = prompt_human_vs_itself
    elif human and not itself:
        prompt_fun = prompt_human_vs_ai
    elif not human and itself:
        prompt_fun = prompt_ai_vs_itself
    else:
        raise ValueError("Invalid configuration.")

    if fable_ids := (cfg.fable_ids or []):
        if not isinstance(fable_ids, list):
            fable_ids = [fable_ids]
        data = data[data["fable_id"].isin(fable_ids)]

    data = data[
        data["generator1"].isin(generators) & data["generator2"].isin(generators)
        ]

    model = get_engine(
        model=predictor,
        kwargs=cfg.model.kwargs or {},
    )

    cfg_dict = OmegaConf.to_container(cfg, resolve=True)
    with Context(
            "evaluate_model",
            storage=storage,
            inputs=cfg_dict,
    ) as c:
        output = []
        for row in tqdm(data.itertuples()):
            id = row.id
            fable_id = row.fable_id
            fable1 = row.fable1
            fable2 = row.fable2

            prompt = prompt_fun(fable1, fable2)
            try:
                prediction_json = query_model(
                    model=model,
                    prompt=prompt,
                )
                prediction = find_and_parse_json_block(
                    prediction_json
                )["my_fable"].lower()
                if prompt_fun == "prompt_human_vs_ai":
                    correct = (
                            prediction == "fable1" and (row.generator1 != "human")
                            or prediction == "fable2" and (row.generator2 != "human")
                    )
                else:
                    correct = (
                            prediction == "fable1" and (predictor == row.generator1)
                            or prediction == "fable2" and (predictor == row.generator2)
                    )
                if correct:
                    correct_prediction = prediction
                else:
                    correct_prediction = {
                        "fable1": "fable2",
                        "fable2": "fable1",
                    }.get(prediction, prediction)
            except Exception as e:
                LOGGER.exception(f"id: {id}, exception: {e}")
                prediction = None
                correct = None
            d_out = {
                "id": id,
                "fable_id": fable_id,
                "fable1": fable1,
                "fable2": fable2,
                "prediction_raw": prediction_json,
                "generator1": row.generator1,
                "generator2": row.generator2,
                "prediction": prediction,
                "correct_prediction": correct_prediction,
                "correct": correct,
                "predictor": predictor,
                "prompt_fun": prompt_fun.__name__,
            }
            output.append(d_out)
            with open("results.jsonl", "a") as f:
                f.write(json.dumps(d_out))
                f.write("\n")

        c.set_result(output)


if __name__ == '__main__':
    main()
